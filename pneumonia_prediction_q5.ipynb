{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yB1uMv7EFwBc",
        "outputId": "7434e5d8-7915-44e5-f471-c8d994257998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "zCJMjRkDJWJg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yannikc/ML4H_project2.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRhpuxwDJUiJ",
        "outputId": "c225dbd0-3378-4ff7-fe06-25e1f0da44bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML4H_project2'...\n",
            "remote: Enumerating objects: 13329, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 13329 (delta 16), reused 51 (delta 10), pack-reused 13270 (from 1)\u001b[K\n",
            "Receiving objects: 100% (13329/13329), 2.09 GiB | 17.74 MiB/s, done.\n",
            "Resolving deltas: 100% (1264/1264), done.\n",
            "Updating files: 100% (23501/23501), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from os import listdir\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "import random\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from os import listdir\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def permute_labels(dataset):\n",
        "  # 1. Copy the original targets\n",
        "  old_targets = dataset.targets.copy()\n",
        "\n",
        "  # 2. Permute them in-place\n",
        "  random.shuffle(old_targets)\n",
        "\n",
        "  # 3. Assign the shuffled labels back\n",
        "  dataset.targets = old_targets\n",
        "\n",
        "  dataset.samples = [\n",
        "      (path, new_label)\n",
        "      for (path, _), new_label in zip(dataset.samples, dataset.targets)\n",
        "  ]\n",
        "  return dataset\n",
        "\n",
        "trainset = ImageFolder(root=\"ML4H_project2/data_part2_processed/train/\", transform=transform)\n",
        "validationset = ImageFolder(root=\"ML4H_project2/data_part2_processed/val/\", transform=transform)\n",
        "testset = ImageFolder(root=\"ML4H_project2/data_part2_processed/test/\", transform=transform)\n",
        "\n",
        "trainset = permute_labels(trainset)\n",
        "validationset= permute_labels(validationset)\n",
        "testset= permute_labels(testset)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "validationloader = DataLoader(validationset, batch_size=32, shuffle=True)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=True)\n",
        "images, labels = next(iter(trainloader))\n",
        "print(images.shape)  # should be [32, 1, 1000, 1000]\n",
        "print(labels.shape)  # should be [32]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JCMsrD0HbwA",
        "outputId": "4a1ec23c-5892-4b87-d8ea-470ad2e050f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 1000, 1000])\n",
            "torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=2, padding=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2, padding=2)\n",
        "        self.conv3 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=2)\n",
        "        self.conv4 = nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2)\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "_XbFA4Z9F5OF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 10"
      ],
      "metadata": {
        "id": "WUJEcmegH16y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for images, labels in tqdm(trainloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float().unsqueeze(1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(trainloader)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in validationloader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels.float().unsqueeze(1))\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(validationloader)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {avg_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5Epbwf1LnlD",
        "outputId": "7d846368-6664-4f14-e721-a17c6c0b0586"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [01:41<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Training Loss: 0.5821, Validation Loss: 0.7493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [01:42<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Training Loss: 0.5781, Validation Loss: 0.8451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [01:41<00:00,  1.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Training Loss: 0.5743, Validation Loss: 0.8142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [01:42<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Training Loss: 0.5729, Validation Loss: 0.7834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [01:42<00:00,  1.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Training Loss: 0.5733, Validation Loss: 0.8074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [01:41<00:00,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Training Loss: 0.5720, Validation Loss: 0.8279\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [01:41<00:00,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Training Loss: 0.5713, Validation Loss: 0.8526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [01:40<00:00,  1.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Training Loss: 0.5721, Validation Loss: 0.8275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [01:41<00:00,  1.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Training Loss: 0.5713, Validation Loss: 0.8490\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 163/163 [01:44<00:00,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Training Loss: 0.5715, Validation Loss: 0.8428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on test set\n",
        "model.eval()\n",
        "test_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in tqdm(testloader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels.float().unsqueeze(1))\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Accuracy calculation\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        correct += (predicted == labels.unsqueeze(1)).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # AUROC and AUPRC calculation\n",
        "        all_preds.extend(outputs.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "avg_test_loss = test_loss / len(testloader)\n",
        "accuracy = correct / total\n",
        "auroc = roc_auc_score(all_labels, all_preds)\n",
        "auprc = average_precision_score(all_labels, all_preds)\n",
        "\n",
        "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Test AUROC: {auroc:.4f}, Test AUPRC: {auprc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJRsxaIALrpn",
        "outputId": "1870c62b-49fc-402d-a11c-aef4b6a97a55"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20/20 [00:09<00:00,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.6999, Test Accuracy: 62.50%\n",
            "Test AUROC: 0.5246, Test AUPRC: 0.6295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the model weights\n",
        "torch.save(model.state_dict(), 'randomized_CNN_weights.pth')"
      ],
      "metadata": {
        "id": "wclh6qMtLt3W"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}